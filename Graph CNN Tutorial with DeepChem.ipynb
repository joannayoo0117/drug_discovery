{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone\n",
    "\n",
    "1. Run Graph CNN with Tox21 (DeepChem Tutorial)\n",
    "2. Change input dataset to DUD-E + PDBBind\n",
    "3. Compare DeepChem GraphCNN (tensorflow) and pyGCN (pytorch) and migrate.\n",
    "4. Change pyGCN and pyGAT to GAGAN \n",
    "\n",
    "The source of this demo is [here](https://deepchem.io/docs/notebooks/graph_convolutional_networks_for_tox21.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joanna/anaconda3/envs/graph/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Building Graph from Molecule (SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "# Load Tox21 dataset\n",
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = tox21_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Output of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of X: <deepchem.feat.mol_graphs.ConvMol object at 0x7fc89f0a7a90>\n",
      "Sample of y: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Sample of w: [0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "X.shape: (784,)\n",
      "y.shape: (784, 12)\n",
      "w.shape: (784, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Sample of X: ' + str(test_dataset.X[0]))\n",
    "print('Sample of y: ' + str(test_dataset.y[0]))\n",
    "print('Sample of w: ' + str(test_dataset.w[0]))\n",
    "\n",
    "\n",
    "X = test_dataset.X\n",
    "y = test_dataset.y\n",
    "w = test_dataset.w\n",
    "\n",
    "print('X.shape: ' + str(X.shape))\n",
    "print('y.shape: ' + str(y.shape))\n",
    "print('w.shape: ' + str(w.shape)) # I think this is the \"transformed\" version of y basically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepchem.trans.transformers.BalancingTransformer at 0x7fc89f0f5b00>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox21_tasks # returns the columns of the dataset \n",
    "transformers # It has BalancingTransformer - it balances positive and negative examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from /tmp/full_smiles_labels.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "Featurizing sample 8000\n",
      "TIMING: featurizing shard 0 took 22.107 s\n",
      "Loading shard 2 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "TIMING: featurizing shard 1 took 3.823 s\n",
      "TIMING: dataset construction took 31.153 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 7.538 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 7.206 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 3.472 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 3.430 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "# Try it with PDBBind\n",
    "\n",
    "pdbbind_tasks, pdbbind_datasets, transformers = dc.molnet.load_pdbbind_grid(featurizer='GraphConv', subset='full')\n",
    "train_dataset_p, valid_dataset_p, test_datase_p = pdbbind_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Code\n",
    "\n",
    "I extracted the code that I would re-use in my own model. Download the data below and untar it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "      <th>mol_id</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX3021</td>\n",
       "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX3020</td>\n",
       "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOX3024</td>\n",
       "      <td>CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX3027</td>\n",
       "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX20800</td>\n",
       "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  \\\n",
       "0    0.0        0.0     1.0           NaN    NaN        0.0            0.0   \n",
       "1    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "2    NaN        NaN     NaN           NaN    NaN        NaN            NaN   \n",
       "3    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "4    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "\n",
       "   SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53    mol_id  \\\n",
       "0     1.0       0.0     0.0     0.0     0.0   TOX3021   \n",
       "1     NaN       0.0     NaN     0.0     0.0   TOX3020   \n",
       "2     0.0       NaN     0.0     NaN     NaN   TOX3024   \n",
       "3     NaN       0.0     NaN     0.0     0.0   TOX3027   \n",
       "4     0.0       0.0     0.0     0.0     0.0  TOX20800   \n",
       "\n",
       "                                              smiles  \n",
       "0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1  \n",
       "1                          CCN1C(=O)NC(c2ccccc2)C1=O  \n",
       "2  CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...  \n",
       "3                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C  \n",
       "4                          CC(O)(P(=O)(O)O)P(=O)(O)O  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison to deepchem load_tox21 module\n",
    "import pandas as pd\n",
    "\n",
    "tox21_df = pd.read_csv('/home/joanna/mindslab/drug_discovery/data/tox21.csv')\n",
    "tox21_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>id</th>\n",
       "      <th>-logKd/Ki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(=O)NC(CCC(=O)[O-])C(=O)[O-]</td>\n",
       "      <td>3zzf</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C[NH2+]CCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1</td>\n",
       "      <td>3gww</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(=O)N1CCCC(C)C1</td>\n",
       "      <td>1w8l</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nc1cccc(C(=O)[O-])c1</td>\n",
       "      <td>3fqa</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(=O)Nc1nnc(S(N)(=O)=O)s1</td>\n",
       "      <td>1zsb</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[NH3+]C(CF)(Cc1c[nH]c2ccccc12)C(=O)[O-]</td>\n",
       "      <td>4obv</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CSCCC([NH3+])C(=O)[O-]</td>\n",
       "      <td>1wkm</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O=C([O-])CC(O)(CC(=O)[O-])C(=O)[O-]</td>\n",
       "      <td>4eu3</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OCC(O)CO</td>\n",
       "      <td>2w97</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C[NH2+]CCCCC([NH3+])C(=O)[O-]</td>\n",
       "      <td>1p0y</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    smiles    id  -logKd/Ki\n",
       "0           CC(=O)NC(CCC(=O)[O-])C(=O)[O-]  3zzf       0.40\n",
       "1  C[NH2+]CCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1  3gww       0.45\n",
       "2                        CC(=O)N1CCCC(C)C1  1w8l       0.49\n",
       "3                     Nc1cccc(C(=O)[O-])c1  3fqa       0.49\n",
       "4               CC(=O)Nc1nnc(S(N)(=O)=O)s1  1zsb       0.60\n",
       "5  [NH3+]C(CF)(Cc1c[nH]c2ccccc12)C(=O)[O-]  4obv       0.75\n",
       "6                   CSCCC([NH3+])C(=O)[O-]  1wkm       0.82\n",
       "7      O=C([O-])CC(O)(CC(=O)[O-])C(=O)[O-]  4eu3       0.82\n",
       "8                                 OCC(O)CO  2w97       0.96\n",
       "9            C[NH2+]CCCCC([NH3+])C(=O)[O-]  1p0y       1.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdbbind_df = pd.read_csv('/home/joanna/mindslab/drug_discovery/data/pdbbind_grid_full.csv')\n",
    "pdbbind_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolfiles\n",
    "from rdkit.Chem import rdmolops\n",
    "\n",
    "\n",
    "test_smiles_seq = 'CCOc1ccc2nc(S(N)(=O)=O)sc2c1'\n",
    "\n",
    "mol = Chem.MolFromSmiles(test_smiles_seq)\n",
    "print(mol.GetNumAtoms())\n",
    "print([atom.GetAtomicNum() for atom in mol.GetAtoms()])\n",
    "print([atom.GetSymbol() for atom in mol.GetAtoms()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change atom list to all atoms\n",
    "possible_atom_list =  ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na', 'Ca',\n",
    "    'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se',\n",
    "    'Ti', 'Zn', 'H', 'Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr', 'Cr', 'Pt','Hg',\n",
    "    'Pb', 'As', 'Unknown']\n",
    "possible_numH_list = [0, 1, 2, 3, 4]\n",
    "possible_valence_list = [0, 1, 2, 3, 4, 5, 6]\n",
    "possible_formal_charge_list = [-3, -2, -1, 0, 1, 2, 3]\n",
    "        \n",
    "possible_degree_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "possible_hybridization_list = [\n",
    "    Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "    Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
    "    Chem.rdchem.HybridizationType.SP3D2\n",
    "]\n",
    "possible_number_radical_e_list = [0, 1, 2]\n",
    "possible_chirality_list = ['R', 'S']\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(\n",
    "            x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def get_atom_features(atom, bool_id_feat=False, explicit_H=False, use_chirality=False):\n",
    "    \"\"\"\n",
    "    From deepchem.feat.graph_features\n",
    "    \"\"\"\n",
    "    if bool_id_feat: return np.array([atom_to_id(atom)])\n",
    "    else:\n",
    "        ## why not one-hot get_formal_charge and get_num_radical_electrons?\n",
    "\n",
    "        \n",
    "        result = one_of_k_encoding_unk(atom.GetSymbol(), possible_atom_list) + \\\n",
    "                 one_of_k_encoding(atom.GetDegree(), possible_degree_list) + \\\n",
    "                 one_of_k_encoding_unk(atom.GetImplicitValence(), possible_valence_list) + \\\n",
    "                [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
    "                 one_of_k_encoding_unk(atom.GetHybridization(), possible_hybridization_list) + \\\n",
    "                [atom.GetIsAromatic()]\n",
    "                \n",
    "        if not explicit_H:\n",
    "            result = result + one_of_k_encoding_unk(atom.GetTotalNumHs(), possible_numH_list)\n",
    "        if use_chirality:\n",
    "            try:\n",
    "                result = result + one_of_k_encoding_unk(atom.GetProp('_CIPCode'), possible_chirality_list) + \\\n",
    "                    [atom.HasProp('_ChiralityPossible')]\n",
    "            except:\n",
    "                result = result + [False, False] + [atom.HasProp('_ChiralityPossible')]\n",
    "                \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comparison to \"featurizer\" in deepchem\n",
    "# featurizer._get_atom_properties gets additional features of the atom so it is ignored for now.\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "def smiles_2_graph(smiles_arr, featurize_fn):\n",
    "    \"\"\"\n",
    "    from deepchem.data.data_loader.featurize_smiles_df\n",
    "    \"\"\"\n",
    "    raw_features = [] # modified\n",
    "    features = []\n",
    "    for ind, elem in enumerate(smiles_arr):\n",
    "        mol = Chem.MolFromSmiles(elem)\n",
    "        if mol:\n",
    "            # what are these lines doing?\n",
    "            # Answer: found in deepchem.data.data_loader featurize_smiles_df\n",
    "            # TODO (ytz) this is a bandage solution to reorder the atoms so\n",
    "            # that they're always in the same canonical order. Presumably this\n",
    "            # should be correctly implemented in the future for graph mols.\n",
    "            \n",
    "            new_order = rdmolfiles.CanonicalRankAtoms(mol)\n",
    "            mol = rdmolops.RenumberAtoms(mol, new_order)\n",
    "            \n",
    "        raw_feature, feature = featurize_fn(mol)\n",
    "        raw_features.append(raw_feature)\n",
    "        features.append(feature)\n",
    "\n",
    "    return raw_features, features\n",
    "\n",
    "def get_graph_from_molecule(mol, use_master_atom=False):\n",
    "    \"\"\"\n",
    "    From ConvMolFeaturizer._featurize\n",
    "    Input:\n",
    "        rdkit.Chem.rdchem.Mol\n",
    "        \n",
    "    Output:\n",
    "        nodes - np.ndarray of shape (num_atoms, num_feat)\n",
    "        canon_adj_list - list. index corresponds to the index of node \n",
    "                         and canon_adj_list[index] corresponds to indices of the nodes that node i is connected to. \n",
    "    \"\"\"\n",
    "    idx_nodes = [(atom.GetIdx(), get_atom_features(atom)) for atom in mol.GetAtoms()]\n",
    "    idx_nodes.sort()\n",
    "    idx, nodes = list(zip(*idx_nodes))\n",
    "    \n",
    "    nodes = np.vstack(nodes)\n",
    "\n",
    "    # Master atom is the \"average\" of all atoms that is connected to all atom\n",
    "    # Introduced in https://arxiv.org/pdf/1704.01212.pdf\n",
    "    if use_master_atom: \n",
    "        master_atom_features = np.expand_dims(np.mean(nodes, axis=0), axis=0)\n",
    "        nodes = np.concatenate([nodes. master_atom_features], axis=0)\n",
    "        \n",
    "    edge_list = [(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()) for bond in mol.GetBonds()]\n",
    "    \n",
    "    canon_adj_list = [[] for _ in range(len(nodes))] # nodes is np 2darray. why len?\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        canon_adj_list[edge[0]].append(edge[1])\n",
    "        canon_adj_list[edge[1]].append(edge[0])\n",
    "        \n",
    "    if use_master_atom:\n",
    "        fake_atom_index = len(nodes) - 1\n",
    "        \n",
    "        for i in range(len(nodes) - 1):\n",
    "            canon_adj_list[i].append(fake_atom_index)\n",
    "        \n",
    "    return (nodes, canon_adj_list), ConvMol(nodes, canon_adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extracted from ConvMol. Do we really need this??\n",
    "\n",
    "def cumulative_sum(l, offset=0):\n",
    "    \"\"\"Returns cumulative sums for set of counts.\n",
    "    Returns the cumulative sums for a set of counts with the first returned value\n",
    "    starting at 0. I.e [3,2,4] -> [0, 3, 5, 9]. Keeps final sum for searching. \n",
    "    Useful for reindexing.\n",
    "    Parameters\n",
    "    ----------\n",
    "    l: list\n",
    "        List of integers. Typically small counts.\n",
    "    \"\"\"\n",
    "    return np.insert(np.cumsum(l), 0, 0) + offset\n",
    "\n",
    "def cumulative_sum_minus_last(l, offset=0):\n",
    "    \"\"\"Returns cumulative sums for set of counts, removing last entry.\n",
    "    Returns the cumulative sums for a set of counts with the first returned value\n",
    "    starting at 0. I.e [3,2,4] -> [0, 3, 5]. Note last sum element 9 is missing.\n",
    "    Useful for reindexing\n",
    "    Parameters\n",
    "    ----------\n",
    "    l: list\n",
    "        List of integers. Typically small counts.\n",
    "    \"\"\"\n",
    "    return np.delete(np.insert(np.cumsum(l), 0, 0), -1) + offset\n",
    "\n",
    "\n",
    "def get_convmol_features(atom_features, adj_list, max_deg, min_deg):\n",
    "    n_atoms, n_feat = atom_features.shape\n",
    "    deg_list = [len(edges) for edges in adj_list]\n",
    "    deg_slice = []\n",
    "    # membership = n_atoms * [0]\n",
    "    \n",
    "    ## start of _deg_sort()\n",
    "    old_ind = range(n_atoms)\n",
    "    new_ind = list(np.lexsort((old_ind, deg_list)))\n",
    "    \n",
    "    # reorder old atom_features\n",
    "    atom_features = atom_features[new_ind, :]\n",
    "    deg_list = [deg_list[i] for i in new_ind]\n",
    "    adj_list = [adj_list[i] for i in new_ind]\n",
    "\n",
    "    # not intuitive way of sorting edges in adj_list\n",
    "    old_to_new = dict(zip(new_ind, old_ind)) # interesting. it's (value, key)\n",
    "    adj_list = [[old_to_new[k] for k in adj_list[i]] for i in range(len_new_ind)]\n",
    "    \n",
    "    # construct adj_lists\n",
    "    deg_array = np.array(deg_list)\n",
    "    deg_adj_lists = (max_deg + 1 - min_deg) * [0]\n",
    "\n",
    "    for deg in range(min_deg, max_deg + 1):\n",
    "        rng = np.array(range(n_atoms))\n",
    "        indices = rng[deg_array == deg]\n",
    "        \n",
    "        to_cat = [adj_list[i] for i in indices]\n",
    "        if len(to_cat) > 0:\n",
    "            adj_list = np.vstack([adj_list[i] for i in indices])\n",
    "            deg_adj_lists[deg - min_deg] = adj_list\n",
    "            \n",
    "        else:\n",
    "            deg_adj_lists[deg - min_deg] = np.zeros([0, deg], dtype=np.int32)\n",
    "            \n",
    "    \n",
    "    # construct slice info \n",
    "    deg_slice = np.zeros([max_deg + 1 - min_deg, 2], dtype=np.int32)\n",
    "    \n",
    "    for deg in range(min_deg, max_deg + 1):\n",
    "        if deg == 0:\n",
    "            deg_size = np.sum(deg_array == deg)\n",
    "        else:\n",
    "            deg_size = deg_adj_lists[deg - min_deg].shape[0]\n",
    "        \n",
    "        deg_slice[deg - min_deg, 1] = deg_size\n",
    "        \n",
    "        # get cumulative indices after the first index\n",
    "        if deg > min_deg: \n",
    "            deg_slice[deg-min_deg, 0] = (deg_slice[deg - min_deg - 1, 0] + deg_slice[deg - min_deg - 1, 1])\n",
    "    \n",
    "    # set indices with zerosized slices to zero to avoid indexing errors\n",
    "    deg_slice[:, 0] *= (deg_slice[:, 1] != 0)\n",
    "    \n",
    "    ## end of _deg_sort()\n",
    "    \n",
    "    deg_id_list = np.array(deg_list) - min_deg\n",
    "    deg_size = [deg_slice[deg - min_deg, 1] for deg in range(min_deg, max_deg + 1)] # This part is equivalent of get_num_atoms_with_deg\n",
    "    \n",
    "    degree_list = [] ## ???? What's the difference bt deg_list vs degree_list?\n",
    "    for i, deg in enumerate(range(min_deg, max_deg+1)):\n",
    "        degree_list.extend([deg] * deg_size[i])\n",
    "    \n",
    "    deg_start = cumulative_sum(deg_size)\n",
    "    \n",
    "    deg_block_indices = np.array([i - deg_start[deg_list[i]] for i in range(n_atoms)])\n",
    "    \n",
    "    return deg_list, deg_adj_lists, deg_slice\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atom_features = smiles_2_graph([test_smiles_seq], featurize_fn=get_graph_from_molecule)[0][0].shape[1]\n",
    "print(num_atom_features)\n",
    "\n",
    "# Why do I have extra one?? cuz i added As"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. GraphConvolution Model in Keras\n",
    "\n",
    "`GraphConv` module in deepchem is using Keras to implement graph convolution.\n",
    "The reference (paper) is not provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.models.graph_models import GraphConvModel\n",
    "model = GraphConvModel(\n",
    "    len(pdbbind_tasks), batch_size=50, mode='classification')\n",
    "# Set nb_epoch=10 for better results.\n",
    "model.fit(train_dataset_p, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
    "print(\"Validation ROC-AUC Score: %f\" % valid_scores[\"mean-roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, Softmax, Dropout, Activation, BatchNormalization\n",
    "\n",
    "class GraphConvModel:\n",
    "    def __init__(self, \n",
    "                 graph_conv_layers=[64, 64], \n",
    "                 dense_layer_size=128,\n",
    "                 dropout=0.0, \n",
    "                 num_atom_features=num_atom_features,\n",
    "                 n_classes=2,\n",
    "                 batch_size=100,\n",
    "                 max_deg=10,\n",
    "                 **kwargs):\n",
    "    \n",
    "        self.dense_layer_size = dense_layer_size\n",
    "        self.graph_conv_layers = graph_conv_layers\n",
    "        self.number_atom_features = num_atom_features\n",
    "        self.n_classes = n_classes\n",
    "        if not isinstance(dropout, collections.Sequence):\n",
    "            dropout = [dropout] * (len(graph_conv_layers) + 1)\n",
    "        if len(dropout) != len(graph_conv_layers) + 1:\n",
    "            raise ValueError('Wrong number of dropout probabilities provided')\n",
    "        self.dropout = dropout\n",
    "        self.max_deg = max_deg\n",
    "        \n",
    "        # Build model\n",
    "        atom_features = Input(shape=(self.number_atom_features,))\n",
    "        degree_slice = Input(shape=(2,), dtype=tf.int32)\n",
    "        membership = Input(shape=tuple(), dtype=tf.int32)\n",
    "        n_samples = Input(shape=tuple(), dtype=tf.int32)\n",
    "        dropout_switch = tf.keras.Input(shape=tuple())\n",
    "        \n",
    "        # What is this part?\n",
    "        self.deg_adjs = []\n",
    "        for i in range(0, self.max_deg + 1): # Why 10?\n",
    "            deg_adj = Input(shape=(i + 1,), dtype=tf.int32)\n",
    "            self.deg_adjs.append(deg_adj)\n",
    "            \n",
    "        in_layer = atom_features\n",
    "        for layer_size, dropout in zip(self.graph_conv_layers, self.dropout):\n",
    "            gc1_in = [in_layer, degree_slice, membership] + self.deg_adjs\n",
    "            gc1 = GraphConv(layer_size, activation_fn=tf.nn.relu)(gc1_in)\n",
    "            batch_norm1 = BatchNormalization(fused=False)(gc1)\n",
    "            \n",
    "            if dropout > 0.0:\n",
    "                batch_norm1 = SwitchedDropout(rate=dropout)([batch_norm1, dropout_switch])\n",
    "            gp_in = [batch_norm1, degree_slice, membership] + self.deg_adjs\n",
    "            in_layer = GraphPool()(gp_in)\n",
    "\n",
    "        dense = Dense(self.dense_layer_size, activation=tf.nn.relu)(in_layer)\n",
    "        batch_norm3 = BatchNormalization(fused=False)(dense)\n",
    "        \n",
    "        if self.dropout[-1] > 0.0:\n",
    "            batch_norm3 = SwitchedDropout(rate=self.dropout[-1])([batch_norm3, dropout_switch])\n",
    "        self.neural_fingerprint = GraphGather(batch_size=batch_size, activation_fn=tf.nn.tanh)(\n",
    "            [batch_norm3, degree_slice, membership] + self.deg_adjs)\n",
    "        \n",
    "        logits = Reshape((1, n_classes))(Dense(self.n_classes))(self.neural_fingerprint)\n",
    "        logits = TrimGraphOutput()([logits, n_samples])\n",
    "        output = Softmax()(logits)\n",
    "        outputs = [output, logit]\n",
    "        output_types = ['prediction', 'loss']\n",
    "        loss = SoftmaxCrossEntropy()\n",
    "        \n",
    "        model = tf.keras.Model(\n",
    "            inputs=[atom_features, degree_slices, membership, n_samples, dropout_switch] + self.deg_adjs,\n",
    "            output=outputs\n",
    "        )\n",
    "        ## TODO The model says this but change it.\n",
    "        ## TODO Check KerasModel's fit \n",
    "        super(GraphConvModel, self).__init__(\n",
    "            model, loss, output_types=output_types, batch_size=batch_size, **kwargs)\n",
    "        \n",
    "        \n",
    "# TODO Implement the layers\n",
    "\n",
    "class GraphConv:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class SwitchedDropout:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "class GraphPool:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "class GraphGather:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "# TODO Study this code. What is ConvMol doing for deg_slice & membership?\n",
    "def default_generator(self,\n",
    "                        dataset,\n",
    "                        epochs=1,\n",
    "                        mode='fit',\n",
    "                        deterministic=True,\n",
    "                        pad_batches=True):\n",
    "    for epoch in range(epochs):\n",
    "        for (X_b, y_b, w_b, ids_b) in dataset.iterbatches(\n",
    "          batch_size=self.batch_size,\n",
    "          deterministic=deterministic,\n",
    "          pad_batches=pad_batches): # what does this do?\n",
    "            if self.mode == 'classification':\n",
    "                y_b = to_one_hot(y_b.flatten(), self.n_classes).reshape(\n",
    "                -1, self.n_tasks, self.n_classes)\n",
    "            multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
    "            n_samples = np.array(X_b.shape[0])\n",
    "            if mode == 'predict':\n",
    "                dropout = np.array(0.0)\n",
    "            else:\n",
    "                dropout = np.array(1.0)\n",
    "            inputs = [\n",
    "                multiConvMol.get_atom_features(), multiConvMol.deg_slice,\n",
    "                np.array(multiConvMol.membership), n_samples, dropout\n",
    "            ]\n",
    "            for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "                inputs.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "            yield (inputs, [y_b], [w_b])\n",
    "        \n",
    "# Why yield?\n",
    "# We should use yield when we want to iterate over a sequence, but donâ€™t want to store the entire sequence in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.tensor_graph import TensorGraph\n",
    "\n",
    "tg = TensorGraph(use_queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Feature\n",
    "\n",
    "atom_features = Feature(shape=(None, 75))\n",
    "degree_slice = Feature(shape=(None, 2), dtype=tf.int32)\n",
    "membership = Feature(shape=(None,), dtype=tf.int32)\n",
    "\n",
    "deg_adjs = []\n",
    "for i in range(0, 10 + 1):\n",
    "    deg_adj = Feature(shape=(None, i + 1), dtype=tf.int32)\n",
    "    deg_adjs.append(deg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Dense, GraphConv, BatchNorm\n",
    "from deepchem.models.tensorgraph.layers import GraphPool, GraphGather\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "gc1 = GraphConv(\n",
    "    64,\n",
    "    activation_fn=tf.nn.relu,\n",
    "    in_layers=[atom_features, degree_slice, membership] + deg_adjs)\n",
    "batch_norm1 = BatchNorm(in_layers=[gc1])\n",
    "gp1 = GraphPool(in_layers=[batch_norm1, degree_slice, membership] + deg_adjs)\n",
    "gc2 = GraphConv(\n",
    "    64,\n",
    "    activation_fn=tf.nn.relu,\n",
    "    in_layers=[gp1, degree_slice, membership] + deg_adjs)\n",
    "batch_norm2 = BatchNorm(in_layers=[gc2])\n",
    "gp2 = GraphPool(in_layers=[batch_norm2, degree_slice, membership] + deg_adjs)\n",
    "dense = Dense(out_channels=128, activation_fn=tf.nn.relu, in_layers=[gp2])\n",
    "batch_norm3 = BatchNorm(in_layers=[dense])\n",
    "readout = GraphGather(\n",
    "    batch_size=batch_size,\n",
    "    activation_fn=tf.nn.tanh,\n",
    "    in_layers=[batch_norm3, degree_slice, membership] + deg_adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.models.tensorgraph.layers import Dense, SoftMax, \\\n",
    "    SoftMaxCrossEntropy, WeightedError, Stack\n",
    "from deepchem.models.tensorgraph.layers import Label, Weights\n",
    "\n",
    "costs = []\n",
    "labels = []\n",
    "for task in range(len(tox21_tasks)):\n",
    "    classification = Dense(\n",
    "        out_channels=2, activation_fn=None, in_layers=[readout])\n",
    "\n",
    "    softmax = SoftMax(in_layers=[classification])\n",
    "    tg.add_output(softmax)\n",
    "\n",
    "    label = Label(shape=(None, 2))\n",
    "    labels.append(label)\n",
    "    cost = SoftMaxCrossEntropy(in_layers=[label, classification])\n",
    "    costs.append(cost)\n",
    "all_cost = Stack(in_layers=costs, axis=1)\n",
    "weights = Weights(shape=(None, len(tox21_tasks)))\n",
    "loss = WeightedError(in_layers=[all_cost, weights])\n",
    "tg.set_loss(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "\n",
    "def data_generator(dataset, epochs=1, predict=False, pad_batches=True):\n",
    "    for epoch in range(epochs):\n",
    "        if not predict:\n",
    "            print('Starting epoch %i' % epoch)\n",
    "        for ind, (X_b, y_b, w_b, ids_b) in enumerate(\n",
    "            dataset.iterbatches(\n",
    "                batch_size, pad_batches=pad_batches, deterministic=True)):\n",
    "            d = {}\n",
    "            for index, label in enumerate(labels):\n",
    "                d[label] = to_one_hot(y_b[:, index])\n",
    "            d[weights] = w_b\n",
    "            multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
    "            d[atom_features] = multiConvMol.get_atom_features()\n",
    "            d[degree_slice] = multiConvMol.deg_slice\n",
    "            d[membership] = multiConvMol.membership\n",
    "            for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "                d[deg_adjs[i - 1]] = multiConvMol.get_deg_adjacency_lists()[i]\n",
    "            yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Epochs set to 1 to render tutorials online.\n",
    "# Set epochs=10 for better results.\n",
    "tg.fit_generator(data_generator(train_dataset, epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(\n",
    "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
    "\n",
    "def reshape_y_pred(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    TensorGraph.Predict returns a list of arrays, one for each output\n",
    "    We also have to remove the padding on the last batch\n",
    "    Metrics taks results of shape (samples, n_task, prob_of_class)\n",
    "    \"\"\"\n",
    "    n_samples = len(y_true)\n",
    "    retval = np.stack(y_pred, axis=1)\n",
    "    return retval[:n_samples]\n",
    "\n",
    "\n",
    "print(\"Evaluating model\")\n",
    "train_predictions = tg.predict_on_generator(data_generator(train_dataset, predict=True))\n",
    "train_predictions = reshape_y_pred(train_dataset.y, train_predictions)\n",
    "train_scores = metric.compute_metric(train_dataset.y, train_predictions, train_dataset.w)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores)\n",
    "\n",
    "valid_predictions = tg.predict_on_generator(data_generator(valid_dataset, predict=True))\n",
    "valid_predictions = reshape_y_pred(valid_dataset.y, valid_predictions)\n",
    "valid_scores = metric.compute_metric(valid_dataset.y, valid_predictions, valid_dataset.w)\n",
    "print(\"Valid ROC-AUC Score: %f\" % valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
